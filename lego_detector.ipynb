{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from google.colab import drive\n",
    "from xml.etree import ElementTree as ET\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive on colab notebook\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data files\n",
    "\n",
    "!unzip \"/content/drive/MyDrive/02 - tagged1.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major variables\n",
    "\n",
    "photos_dir = '/content/photos'\n",
    "renders_dir = '/content/renders'\n",
    "\n",
    "# photos_dir = 'content/photos' # running locally\n",
    "# renders_dir = 'content/renders' # running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    '''\n",
    "    Returns a list of images and labels for each image\n",
    "    '''\n",
    "    image_paths = []\n",
    "    num_legos = []\n",
    "    for subdir, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                n = int(subdir.split(os.sep)[-1])\n",
    "                image_paths.append(os.path.join(subdir, file))\n",
    "                num_legos.append(n)\n",
    "    combined = list(zip(image_paths, num_legos))\n",
    "    combined.sort()\n",
    "    image_paths, num_legos = zip(*combined)\n",
    "    image_paths = np.asarray(image_paths)\n",
    "    num_legos = torch.Tensor(num_legos).to(torch.int64)\n",
    "    return image_paths, num_legos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    '''\n",
    "    Read the xml file and return the bounding box coordinates\n",
    "    '''\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    bounding_boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "        bounding_boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_xml(image_paths):\n",
    "    '''\n",
    "    Parse all XML files corresponding to the given image paths.\n",
    "    '''\n",
    "    bounding_boxes = []\n",
    "    for img_path in image_paths:\n",
    "        xml_path = img_path.replace('.jpg', '.xml')\n",
    "        bounding_boxes.append(parse_xml(xml_path))\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "image_paths, num_legos = load_data(photos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse bounding boxes for all images\n",
    "\n",
    "bounding_boxes = parse_all_xml(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in overall data\n",
    "\n",
    "plt.hist(num_legos, bins=range(1, max(num_legos)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of Legos')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Legos Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with defined train test split\n",
    "\n",
    "train_test_split = np.genfromtxt('/content/drive/MyDrive/train_test_split.csv', delimiter=',', dtype=None, encoding=None)\n",
    "# train_test_split = np.genfromtxt('content/train_test_split.csv', delimiter=',', dtype=None, encoding=None) # running locally\n",
    "\n",
    "train_test_ids = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "for index, row in enumerate(train_test_split):\n",
    "    if row[1] == '1':\n",
    "      train_test_ids['test'].append(index - 1)\n",
    "    elif row[1] == '0':\n",
    "      train_test_ids['train'].append(index - 1)\n",
    "\n",
    "len(train_test_ids['train']), len(train_test_ids['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in training data\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of Legos')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Legos Distribution (Training)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling of larger classes in training data\n",
    "\n",
    "indices1 = []\n",
    "indices2 = []\n",
    "\n",
    "for i in train_test_ids['train']:\n",
    "    if num_legos[i] == 1:\n",
    "        indices1.append(i)\n",
    "    elif num_legos[i] == 2:\n",
    "        indices2.append(i)\n",
    "        \n",
    "np.random.shuffle(indices1, )\n",
    "np.random.shuffle(indices2, )\n",
    "\n",
    "leftovers1 = indices1[100:]\n",
    "leftovers2 = indices2[100:]\n",
    "\n",
    "for i in leftovers1:\n",
    "    train_test_ids['train'].remove(i)\n",
    "for i in leftovers2:\n",
    "    train_test_ids['train'].remove(i)\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of Legos')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Legos Distribution (After Undersampling)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling of smaller classes in training data - augmentation\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# TODO: apply augmentation to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "\n",
    "indices = train_test_ids['test']\n",
    "np.random.shuffle(indices, )\n",
    "\n",
    "test_size = 0.4 * len(indices)\n",
    "split = int(np.floor(test_size))\n",
    "train_test_ids['valid'], train_test_ids['test'] = indices[split:], indices[:split]\n",
    "\n",
    "len(train_test_ids['train']), len(train_test_ids['valid']), len(train_test_ids['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegosDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the legos dataset\n",
    "    '''\n",
    "    def __init__(self, images_filenames, num_legos, bounding_boxes, transform=None):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.transform = transform\n",
    "        self.labels = num_legos\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "        label = self.labels[idx]\n",
    "        bounding_boxes = self.bounding_boxes[idx]\n",
    "        image = cv2.imread(image_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        scale_w = 224.0 / original_width\n",
    "        scale_h = 224.0 / original_height\n",
    "        scaled_boxes = []\n",
    "        for box in bounding_boxes:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            x_min = int(x_min * scale_w)\n",
    "            y_min = int(y_min * scale_h)\n",
    "            x_max = int(x_max * scale_w)\n",
    "            y_max = int(y_max * scale_h)\n",
    "            scaled_boxes.append([x_min, y_min, x_max, y_max])\n",
    "        target = {\n",
    "            'boxes': torch.tensor(scaled_boxes, dtype=torch.float32),\n",
    "            'labels': torch.ones((label,), dtype=torch.int64)\n",
    "        }\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding boxes for train, valid, and test sets\n",
    "\n",
    "train_boxes = [bounding_boxes[i] for i in train_test_ids['train']]\n",
    "valid_boxes = [bounding_boxes[i] for i in train_test_ids['valid']]\n",
    "test_boxes = [bounding_boxes[i] for i in train_test_ids['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid and test sets\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = LegosDataset(image_paths[train_test_ids['train']], num_legos[train_test_ids['train']], train_boxes, transform=transform)\n",
    "valid_dataset = LegosDataset(image_paths[train_test_ids['valid']], num_legos[train_test_ids['valid']], valid_boxes, transform=transform)\n",
    "test_dataset = LegosDataset(image_paths[train_test_ids['test']], num_legos[train_test_ids['test']], test_boxes, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cpu or gpu device for training\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster r-cnn model\n",
    "\n",
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "num_classes = 2\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model in device\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(dataloader, model, optimizer=None, is_train=True):\n",
    "    '''\n",
    "    Perform one epoch of training/validation/testing\n",
    "    '''\n",
    "    if is_train:\n",
    "        assert optimizer is not None, \"When training, please provide an optimizer\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for batch, (images, targets) in enumerate(tqdm(dataloader)):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += losses.item()\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, optimizer, train_history=None, val_history=None):\n",
    "    '''\n",
    "    Train the model\n",
    "    '''\n",
    "    if train_history is None:\n",
    "        train_history = {'loss': []}\n",
    "    if val_history is None:\n",
    "        val_history = {'loss': []}\n",
    "    best_val_loss = np.inf\n",
    "    print(\"Start training...\")\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"Epoch {t+1}/{num_epochs}\")\n",
    "        train_loss = epoch_iter(train_dataloader, model, optimizer, is_train=True)\n",
    "        print(f\"Train loss: {train_loss:.3f}\")\n",
    "        val_loss = epoch_iter(validation_dataloader, model, is_train=False)\n",
    "        print(f\"Validation loss: {val_loss:.3f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_dict = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': t\n",
    "            }\n",
    "            torch.save(save_dict, model_name + '_best_model.pth')\n",
    "        save_dict = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': t\n",
    "        }\n",
    "        torch.save(save_dict, model_name + '_latest_model.pth')\n",
    "        train_history['loss'].append(train_loss)\n",
    "        val_history['loss'].append(val_loss)\n",
    "    print(\"Finished\")\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation history\n",
    "\n",
    "train_history = {'loss': []}\n",
    "val_history = {'loss': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_layers(model, layers_to_unfreeze):\n",
    "    '''\n",
    "    Unfreeze the specified layers in the model\n",
    "    '''\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_unfreeze):\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head\n",
    "\n",
    "unfreeze_layers(model, ['roi_heads.box_predictor'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.roi_heads.box_predictor.parameters(), lr=1e-4)\n",
    "num_epochs = 5\n",
    "\n",
    "train_history, val_history = train(\n",
    "                                model,\n",
    "                                'lego_detector_head',\n",
    "                                num_epochs,\n",
    "                                train_dataloader,\n",
    "                                valid_dataloader,\n",
    "                                optimizer,\n",
    "                                train_history,\n",
    "                                val_history\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN\n",
    "\n",
    "rpn_layers = [layer[0] for layer in list(model.named_parameters()) if 'rpn' in layer[0]]\n",
    "unfreeze_layers(model, rpn_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "train_history, val_history = train(\n",
    "                              model,\n",
    "                              'lego_detector_rpn',\n",
    "                              num_epochs,\n",
    "                              train_dataloader,\n",
    "                              valid_dataloader,\n",
    "                              optimizer,\n",
    "                              train_history,\n",
    "                              val_history\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN + backbone\n",
    "\n",
    "backbone_layers = [layer[0] for layer in list(model.named_parameters()) if 'backbone' in layer[0]]\n",
    "unfreeze_layers(model, backbone_layers)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "num_epochs = 10\n",
    "\n",
    "train_history, val_history = train(\n",
    "    model,\n",
    "    'lego_detector_final',\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    optimizer,\n",
    "    train_history,\n",
    "    val_history\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training evolution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingHistory(train_history, val_history):\n",
    "    '''\n",
    "    Plot the training history of the model\n",
    "    '''\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(train_history['loss'], label='train')\n",
    "    plt.plot(val_history['loss'], label='val')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training history\n",
    "\n",
    "plotTrainingHistory(train_history, val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "checkpoint = torch.load('lego_detector_best_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "\n",
    "test_loss = epoch_iter(test_dataloader, model, is_train=False)\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataloader):\n",
    "    '''\n",
    "    Display images along with their true and predicted bounding boxes\n",
    "    '''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            outputs = model(images)\n",
    "            for img, output, target in zip(images, outputs, targets):\n",
    "                img = img.cpu().numpy().transpose((1, 2, 0))\n",
    "                img = F.to_pil_image(torch.tensor(img))\n",
    "                fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "                ax.imshow(img)\n",
    "                for box in target['boxes']:\n",
    "                    box = box.cpu().numpy()\n",
    "                    rect = patches.Rectangle(\n",
    "                        (box[0], box[1]), \n",
    "                        box[2] - box[0], \n",
    "                        box[3] - box[1], \n",
    "                        linewidth=2, \n",
    "                        edgecolor='g', \n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "                    if score > 0.5:\n",
    "                        box = box.cpu().numpy()\n",
    "                        rect = patches.Rectangle(\n",
    "                            (box[0], box[1]), \n",
    "                            box[2] - box[0], \n",
    "                            box[3] - box[1], \n",
    "                            linewidth=2, \n",
    "                            edgecolor='b', \n",
    "                            facecolor='none'\n",
    "                        )\n",
    "                        ax.add_patch(rect)\n",
    "                        ax.text(box[0], box[1], f'{label.item()}: {score:.2f}', bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "                plt.title(f'True (Green) and Predicted (Blue) Bounding Boxes')\n",
    "                plt.axis('off')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view predictions\n",
    "\n",
    "show_predictions(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
