{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Detection - Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from google.colab import drive\n",
    "from xml.etree import ElementTree as ET\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.ops.boxes as box_ops\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive on colab notebook\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data files\n",
    "\n",
    "!unzip \"/content/drive/MyDrive/02 - tagged1.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major variables\n",
    "\n",
    "photos_dir = '/content/photos'\n",
    "renders_dir = '/content/renders'\n",
    "\n",
    "# photos_dir = 'content/photos' # running locally\n",
    "# renders_dir = 'content/renders' # running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    '''\n",
    "    Returns a list of images and labels for each image\n",
    "    '''\n",
    "    image_paths = []\n",
    "    num_legos = []\n",
    "    for subdir, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                n = int(subdir.split(os.sep)[-1])\n",
    "                image_paths.append(os.path.join(subdir, file))\n",
    "                num_legos.append(n)\n",
    "    combined = list(zip(image_paths, num_legos))\n",
    "    combined.sort()\n",
    "    image_paths, num_legos = zip(*combined)\n",
    "    image_paths = np.asarray(image_paths)\n",
    "    num_legos = torch.Tensor(num_legos).to(torch.int64)\n",
    "    return image_paths, num_legos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    '''\n",
    "    Read the xml file and return the bounding box coordinates\n",
    "    '''\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    bounding_boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "        bounding_boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_xml(image_paths):\n",
    "    '''\n",
    "    Parse all XML files corresponding to the given image paths.\n",
    "    '''\n",
    "    bounding_boxes = []\n",
    "    for img_path in image_paths:\n",
    "        xml_path = img_path.replace('.jpg', '.xml')\n",
    "        bounding_boxes.append(parse_xml(xml_path))\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "image_paths, num_legos = load_data(photos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse bounding boxes for all images\n",
    "\n",
    "bounding_boxes = parse_all_xml(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in overall data\n",
    "\n",
    "plt.hist(num_legos, bins=range(1, max(num_legos)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with defined train test split\n",
    "\n",
    "train_test_split = np.genfromtxt('/content/drive/MyDrive/train_test_split.csv', delimiter=',', dtype=None, encoding=None)\n",
    "# train_test_split = np.genfromtxt('content/train_test_split.csv', delimiter=',', dtype=None, encoding=None) # running locally\n",
    "\n",
    "train_test_ids = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "for index, row in enumerate(train_test_split):\n",
    "    if row[1] == '1':\n",
    "      train_test_ids['test'].append(index - 1)\n",
    "    elif row[1] == '0':\n",
    "      train_test_ids['train'].append(index - 1)\n",
    "\n",
    "len(train_test_ids['train']), len(train_test_ids['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in training data\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Training Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling of larger classes in training data\n",
    "\n",
    "indices1 = []\n",
    "indices2 = []\n",
    "\n",
    "for i in train_test_ids['train']:\n",
    "    if num_legos[i] == 1:\n",
    "        indices1.append(i)\n",
    "    elif num_legos[i] == 2:\n",
    "        indices2.append(i)\n",
    "        \n",
    "np.random.shuffle(indices1, )\n",
    "np.random.shuffle(indices2, )\n",
    "\n",
    "leftovers1 = indices1[100:]\n",
    "leftovers2 = indices2[100:]\n",
    "\n",
    "for i in leftovers1:\n",
    "    train_test_ids['train'].remove(i)\n",
    "for i in leftovers2:\n",
    "    train_test_ids['train'].remove(i)\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Training Distribution (Undersampling)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "\n",
    "indices = train_test_ids['test']\n",
    "np.random.shuffle(indices, )\n",
    "\n",
    "test_size = 0.4 * len(indices)\n",
    "split = int(np.floor(test_size))\n",
    "train_test_ids['valid'], train_test_ids['test'] = indices[split:], indices[:split]\n",
    "\n",
    "len(train_test_ids['train']), len(train_test_ids['valid']), len(train_test_ids['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding boxes for train, valid, and test sets\n",
    "\n",
    "train_boxes = [bounding_boxes[i] for i in train_test_ids['train']]\n",
    "valid_boxes = [bounding_boxes[i] for i in train_test_ids['valid']]\n",
    "test_boxes = [bounding_boxes[i] for i in train_test_ids['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegosDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the legos dataset\n",
    "    '''\n",
    "    def __init__(self, images_filenames, num_legos, bounding_boxes, transforms=[], augmented=[]):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.labels = num_legos\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "        self.transforms = transforms\n",
    "        self.augmented = augmented\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        image_filename = self.images_filenames[id]\n",
    "        label = self.labels[id]\n",
    "        bounding_boxes = self.bounding_boxes[id]\n",
    "        image = cv2.imread(image_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        transformation = self.transforms[self.augmented[id]]\n",
    "        image = transformation(image)\n",
    "        scale_w = 224.0 / original_width\n",
    "        scale_h = 224.0 / original_height\n",
    "        scaled_boxes = []\n",
    "        for box in bounding_boxes:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            x_min = int(x_min * scale_w)\n",
    "            y_min = int(y_min * scale_h)\n",
    "            x_max = int(x_max * scale_w)\n",
    "            y_max = int(y_max * scale_h)\n",
    "            scaled_boxes.append([x_min, y_min, x_max, y_max])\n",
    "        target = {\n",
    "            'boxes': torch.tensor(scaled_boxes, dtype=torch.float32),\n",
    "            'labels': torch.ones((label,), dtype=torch.int64)\n",
    "        }\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid and test sets\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = LegosDataset(image_paths[train_test_ids['train']], num_legos[train_test_ids['train']], train_boxes, \n",
    "                             transforms=[transform, augment], augmented=[0]*len(image_paths[train_test_ids['train']]))\n",
    "\n",
    "valid_dataset = LegosDataset(image_paths[train_test_ids['valid']], num_legos[train_test_ids['valid']], valid_boxes, \n",
    "                             transforms=[transform], augmented=[0]*len(image_paths[train_test_ids['valid']]))\n",
    "\n",
    "test_dataset = LegosDataset(image_paths[train_test_ids['test']], num_legos[train_test_ids['test']], test_boxes, \n",
    "                            transforms=[transform], augmented=[0]*len(image_paths[train_test_ids['test']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_paths, num_legos, bounding_boxes, copies=5):\n",
    "    '''\n",
    "    Generate more data by copying images with more than 6 legos\n",
    "    '''\n",
    "    new_image_paths = []\n",
    "    new_num_legos = []\n",
    "    new_bounding_boxes = []\n",
    "    for id in range(len(image_paths)):\n",
    "        if num_legos[id] >= 6:\n",
    "            for n in range(copies):\n",
    "                new_image_paths.append(image_paths[id])\n",
    "                new_num_legos.append(num_legos[id])\n",
    "                new_bounding_boxes.append(bounding_boxes[id])\n",
    "    return new_image_paths, new_num_legos, new_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling of smaller classes in training data - augmentation\n",
    "\n",
    "new_image_paths, new_num_legos, new_bounding_boxes = generate_data(\n",
    "                                                        image_paths[train_test_ids['train']], \n",
    "                                                        num_legos[train_test_ids['train']], \n",
    "                                                        train_boxes\n",
    "                                                    )\n",
    "\n",
    "for img, lbl, bbox in zip(new_image_paths, new_num_legos, new_bounding_boxes):\n",
    "    train_dataset.images_filenames = np.append(train_dataset.images_filenames, img)\n",
    "    train_dataset.labels = torch.cat((train_dataset.labels, torch.tensor([lbl], dtype=torch.int64)))\n",
    "    train_dataset.bounding_boxes.append(bbox)\n",
    "\n",
    "train_dataset.augmented.extend([1] * len(new_image_paths))\n",
    "\n",
    "num_legos_train = train_dataset.labels\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Training Distribution (Oversampling)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cpu or gpu device for training\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster r-cnn model\n",
    "\n",
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "num_classes = 2\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model in device\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map(predictions, targets):\n",
    "    '''\n",
    "    Compute the Mean Average Precision (mAP) for the given predictions and targets\n",
    "    '''\n",
    "    pred_boxes = [pred['boxes'].cpu() for pred in predictions]\n",
    "    pred_scores = [pred['scores'].cpu() for pred in predictions]\n",
    "    gt_boxes = [target['boxes'].cpu() for target in targets]\n",
    "    pred_boxes_flat = torch.cat(pred_boxes, dim=0)\n",
    "    pred_scores_flat = torch.cat(pred_scores, dim=0)\n",
    "    gt_boxes_flat = torch.cat(gt_boxes, dim=0)\n",
    "    iou_matrix = box_ops.box_iou(pred_boxes_flat, gt_boxes_flat)\n",
    "    true_positives = torch.sum(iou_matrix >= 0.5, dim=1)\n",
    "    false_positives = torch.sum(iou_matrix < 0.5, dim=1)\n",
    "    false_negatives = gt_boxes_flat.shape[0] - true_positives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    map_score = precision.mean().item()\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(dataloader, model, optimizer=None, is_train=True):\n",
    "    '''\n",
    "    Perform one epoch of training/validation/testing\n",
    "    '''\n",
    "    if is_train:\n",
    "        assert optimizer is not None, \"When training, please provide an optimizer\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_map = 0.0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for batch, (images, targets) in enumerate(tqdm(dataloader)):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            if is_train:\n",
    "                loss_data = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_data.values())\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += losses.item()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(images)\n",
    "                    map_score = compute_map(predictions, targets)\n",
    "                    total_map += map_score\n",
    "    avg_loss = total_loss / num_batches if is_train else None\n",
    "    avg_map = total_map / num_batches if not is_train else None\n",
    "    return avg_loss, avg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, optimizer, train_history=None, val_history=None):\n",
    "    '''\n",
    "    Train the model\n",
    "    '''\n",
    "    if train_history is None:\n",
    "        train_history = {'loss': []}\n",
    "    if val_history is None:\n",
    "        val_history = {'map': []}\n",
    "    best_val_map = -np.inf\n",
    "    print(\"Start training...\")\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"Epoch {t+1}/{num_epochs}\")\n",
    "        train_loss, _ = epoch_iter(train_dataloader, model, optimizer, is_train=True)\n",
    "        print(f\"Train loss: {train_loss:.3f}\")\n",
    "        _, val_map = epoch_iter(validation_dataloader, model, is_train=False)\n",
    "        print(f\"Validation mAP: {val_map:.3f}\")\n",
    "        if val_map > best_val_map:\n",
    "            best_val_map = val_map\n",
    "            save_dict = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': t\n",
    "            }\n",
    "            torch.save(save_dict, model_name + '_best_model.pth')\n",
    "        save_dict = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': t\n",
    "        }\n",
    "        torch.save(save_dict, model_name + '_latest_model.pth')\n",
    "        train_history['loss'].append(train_loss)\n",
    "        val_history['map'].append(val_map)\n",
    "    print(\"Finished\")\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation history\n",
    "\n",
    "train_history = {'loss': []}\n",
    "val_history = {'map': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model layers\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "head_layers = ['roi_heads.box_predictor']\n",
    "rpn_layers = [layer[0] for layer in list(model.named_parameters()) if 'rpn' in layer[0]]\n",
    "backbone_layers = [layer[0] for layer in list(model.named_parameters()) if 'backbone' in layer[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_layers(model, layers_to_unfreeze):\n",
    "    '''\n",
    "    Unfreeze the specified layers in the model\n",
    "    '''\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_unfreeze):\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head\n",
    "\n",
    "unfreeze_layers(model, head_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.roi_heads.box_predictor.parameters(), lr=1e-4)\n",
    "num_epochs = 5\n",
    "\n",
    "train_history, val_history = train(\n",
    "                                model,\n",
    "                                'lego_detector',\n",
    "                                num_epochs,\n",
    "                                train_dataloader,\n",
    "                                valid_dataloader,\n",
    "                                optimizer,\n",
    "                                train_history,\n",
    "                                val_history\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "checkpoint = torch.load('lego_detector_latest_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "unfreeze_layers(model, head_layers)\n",
    "unfreeze_layers(model, rpn_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "train_history, val_history = train(\n",
    "                              model,\n",
    "                              'lego_detector',\n",
    "                              num_epochs,\n",
    "                              train_dataloader,\n",
    "                              valid_dataloader,\n",
    "                              optimizer,\n",
    "                              train_history,\n",
    "                              val_history\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN + backbone\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "checkpoint = torch.load('lego_detector_latest_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "unfreeze_layers(model, head_layers)\n",
    "unfreeze_layers(model, rpn_layers)\n",
    "unfreeze_layers(model, backbone_layers)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "num_epochs = 10\n",
    "\n",
    "train_history, val_history = train(\n",
    "                              model,\n",
    "                              'lego_detector',\n",
    "                              num_epochs,\n",
    "                              train_dataloader,\n",
    "                              valid_dataloader,\n",
    "                              optimizer,\n",
    "                              train_history,\n",
    "                              val_history\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training evolution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingHistory(train_history, val_history):\n",
    "    '''\n",
    "    Plot the training history of the model\n",
    "    '''\n",
    "    pass\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training history\n",
    "\n",
    "plotTrainingHistory(train_history, val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "checkpoint = torch.load('lego_detector_best_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "\n",
    "_, test_map = epoch_iter(test_dataloader, model, is_train=False)\n",
    "print(f\"Test mAP: {test_map:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataloader):\n",
    "    '''\n",
    "    Display images along with their true and predicted bounding boxes\n",
    "    '''\n",
    "    pass\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view predictions\n",
    "\n",
    "show_predictions(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
