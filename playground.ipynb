{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main paths\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# store images in json\n",
    "\n",
    "image_files = [file for file in os.listdir(images_dir) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "data = {\n",
    "    'image_files': image_files\n",
    "}\n",
    "\n",
    "with open(input, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an image\n",
    "\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index = 0\n",
    "\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "original_image = cv2.resize(original_image, (0, 0), fx = 0.15, fy = 0.15)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray and hsv versions\n",
    "\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('HSV', hsv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean filter\n",
    "\n",
    "mean = cv2.blur(original_image, (4,4))\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Mean', mean)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian filter\n",
    "\n",
    "gaussian = cv2.GaussianBlur(original_image, (5, 5), 0)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Gaussian', gaussian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median filter\n",
    "\n",
    "median = cv2.medianBlur(original_image, 5)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Median', median)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilateral filter\n",
    "\n",
    "bilateral = cv2.bilateralFilter(original_image, 9, 75, 75)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Bilateral', bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom convulotion\n",
    "\n",
    "gray = gray_image / 255\n",
    "\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 4, -1],\n",
    "                   [0, -1, 0]])\n",
    "\n",
    "convolution = ndimage.convolve(gray, kernel)\n",
    "\n",
    "cv2.imshow('Gray', gray)\n",
    "cv2.imshow('Convulotion', convolution)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms equalization\n",
    "\n",
    "histogram_equalization = cv2.equalizeHist(gray_image)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Histogram equalization', histogram_equalization)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms equalization with color\n",
    "\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
    "\n",
    "histogram_equalization = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow('HSV', hsv)\n",
    "cv2.imshow('Histogram equalization', histogram_equalization)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "image_CLAHE = clahe.apply(gray_image)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('CLAHE', image_CLAHE)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE with color\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "hsv[:,:,2] = clahe.apply(hsv[:,:,2])\n",
    "\n",
    "image_CLAHE = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow('HSV', hsv)\n",
    "cv2.imshow('CLAHE', image_CLAHE)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge and line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel filter\n",
    "\n",
    "sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel with XY combined\n",
    "\n",
    "sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, dx=1, dy=1, ksize=5)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Sobel XY', sobel_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoG\n",
    "\n",
    "laplacian = cv2.Laplacian(gray_image, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('LoG', laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoG with Gaussian Blur\n",
    "\n",
    "gaussian = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "laplacian = cv2.Laplacian(gaussian, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('LoG with Gaussian Blur', laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoG\n",
    "\n",
    "gaussian_1 = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "gaussian_2 = cv2.GaussianBlur(gray_image, (3, 3), 0)\n",
    "\n",
    "difference = gaussian_1 - gaussian_2\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('DoG', difference)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny edge detection\n",
    "\n",
    "canny = cv2.Canny(gray_image, 30, 50)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough line transform\n",
    "\n",
    "canny = cv2.Canny(gray_image, 30, 50)\n",
    "\n",
    "bgr_copy = cv2.cvtColor(canny, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "num_votes = 60\n",
    "\n",
    "lines = cv2.HoughLines(canny, 1, np.pi / 180, num_votes, None, 0, 0)\n",
    "\n",
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "        cv2.line(bgr_copy, pt1, pt2, (255,0,0), 3)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.imshow('Image', bgr_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harris corner detection\n",
    "\n",
    "gray = np.float32(gray_image)\n",
    "\n",
    "neighbourhood = 2\n",
    "aperture = 3\n",
    "free_param = 0.04\n",
    "dst = cv2.cornerHarris(gray, neighbourhood, aperture, free_param)\n",
    "\n",
    "dst = cv2.dilate(dst, None)\n",
    "\n",
    "thr = 0.01\n",
    "\n",
    "image_copy = original_image.copy()\n",
    "\n",
    "image_copy[dst > thr*dst.max()] = [0,0,255]\n",
    "\n",
    "harris = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Harris', harris)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shi-tomasi corner detection\n",
    "\n",
    "max_corners = 200\n",
    "quality = 0.01\n",
    "mindist = 10\n",
    "corners = cv2.goodFeaturesToTrack(gray, max_corners, quality, mindist, blockSize=neighbourhood, k=free_param)\n",
    "corners = np.intp(corners)\n",
    "\n",
    "shi_tomasi = original_image.copy()\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(shi_tomasi, (x,y), 3, 255, -1)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Shi-Tomasi', shi_tomasi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST corner detector\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "kp = fast.detect(original_image, None)\n",
    "fast_with_nms = cv2.drawKeypoints(original_image, kp, None, color=(255,0,0))\n",
    "\n",
    "fast.setNonmaxSuppression(0)\n",
    "kp = fast.detect(original_image, None)\n",
    "fast_without_nms = cv2.drawKeypoints(original_image, kp, None, color=(255,0,0))\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('FAST w/ NMS', fast_with_nms)\n",
    "cv2.imshow('FAST w/o NMS', fast_without_nms)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT blob detector\n",
    "\n",
    "image_copy = original_image.copy()\n",
    "gray_copy = gray_image.copy()\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "kp = sift.detect(gray_copy, None)\n",
    "\n",
    "sift_image = cv2.drawKeypoints(gray_copy, kp, image_copy, (-1, -1, -1), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Gray', gray_copy)\n",
    "cv2.imshow('SIFT', sift_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orb blob detector\n",
    "\n",
    "image_copy = original_image.copy()\n",
    "gray_copy = gray_image.copy()\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp = orb.detect(image_copy, None)\n",
    "\n",
    "kp, des = orb.compute(image_copy, kp)\n",
    "\n",
    "orb_image = cv2.drawKeypoints(image_copy, kp, None, (-1, -1, -1), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Gray', gray_copy)\n",
    "cv2.imshow('ORB', orb_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warping and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affine transformation\n",
    "\n",
    "ori_coord = np.array([[0, 0], [original_image.shape[1] - 1, 0], [0, original_image.shape[0] - 1]]).astype(np.float32)\n",
    "\n",
    "tar_coord = np.array([[0, original_image.shape[1]*0.33], [original_image.shape[1]*0.85, original_image.shape[0]*0.25], [original_image.shape[1]*0.15, original_image.shape[0]*0.7]]).astype(np.float32)\n",
    "\n",
    "warp_mat = cv2.getAffineTransform(ori_coord, tar_coord)\n",
    "\n",
    "warp = cv2.warpAffine(original_image, warp_mat, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Warped', warp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation matrix\n",
    "\n",
    "rot_mat = cv2.getRotationMatrix2D(center=(original_image.shape[1] // 2, original_image.shape[0] // 2), angle=90, scale=1)\n",
    "\n",
    "rotation = cv2.warpAffine(original_image, rot_mat, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Rotated', rotation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation with affine transformation\n",
    "\n",
    "ori_coord = np.array([[0, 0], [original_image.shape[1] - 1, 0], [0, original_image.shape[0] - 1]]).astype(np.float32)\n",
    "\n",
    "tar_coord = np.array([[original_image.shape[1] - 1, 0], [original_image.shape[1] - 1, original_image.shape[0] - 1], [0, 0]]).astype(np.float32)\n",
    "\n",
    "warp_mat = cv2.getAffineTransform(ori_coord, tar_coord)\n",
    "\n",
    "warp = cv2.warpAffine(original_image, warp_mat, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Warped', warp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation matrix\n",
    "\n",
    "translation_matrix = np.array([\n",
    "    [1, 0, 100],\n",
    "    [0, 1, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_translation = cv2.warpAffine(original_image, translation_matrix, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Warped', warp_translation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otsu thresholding\n",
    "\n",
    "ret, th_global = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ret, th_otsu = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Global Threshold', th_global)\n",
    "cv2.imshow('Otsu Threshold', th_otsu)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otus thresholding with gaussian blur\n",
    "\n",
    "img_blur = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "ret, th_otsu = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Blurred', img_blur)\n",
    "cv2.imshow('Otsu Threshold', th_otsu)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive threshold\n",
    "\n",
    "th_adaptive = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Adaptive Mean', th_adaptive)\n",
    "cv2.imshow('Otsu Threshold', th_otsu)\n",
    "cv2.imshow('Global Threshold', th_global)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive threshold with different blur sizes\n",
    "\n",
    "img_blur_3 = cv2.GaussianBlur(gray_image, (3, 3), 0)\n",
    "\n",
    "img_blur_5 = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "img_blur_7 = cv2.GaussianBlur(gray_image, (7, 7), 0)\n",
    "\n",
    "th_adaptive_3 = cv2.adaptiveThreshold(img_blur_3, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "th_adaptive_5 = cv2.adaptiveThreshold(img_blur_5, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "th_adaptive_7 = cv2.adaptiveThreshold(img_blur_7, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('Adaptive Mean 3x3', th_adaptive_3)\n",
    "cv2.imshow('Adaptive Mean 5x5', th_adaptive_5)\n",
    "cv2.imshow('Adaptive Mean 7x7', th_adaptive_7)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (490, 367, 3)\n",
      "Current shape: (179830, 3)\n"
     ]
    }
   ],
   "source": [
    "# segmentation with k-means\n",
    "\n",
    "image_copy = original_image.copy()\n",
    "\n",
    "print(f\"Previous shape: {image_copy.shape}\")\n",
    "\n",
    "reshaped_image = image_copy.reshape((-1,3))\n",
    "reshaped_image = np.float32(reshaped_image)\n",
    "\n",
    "print(f\"Current shape: {reshaped_image.shape}\")\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "k = 4\n",
    "\n",
    "ret, label, center = cv2.kmeans(reshaped_image, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation with k-means\n",
    "\n",
    "center = np.uint8(center)\n",
    "result = center[label.flatten()]\n",
    "result = result.reshape((image_copy.shape))\n",
    "\n",
    "cv2.imshow('Image', image_copy)\n",
    "cv2.imshow('K-Means', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation with k-means (different number of clusters)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "k = 2\n",
    "\n",
    "ret, label, center = cv2.kmeans(reshaped_image, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "center = np.uint8(center)\n",
    "result = center[label.flatten()]\n",
    "result = result.reshape((image_copy.shape))\n",
    "\n",
    "cv2.imshow('Image', image_copy)\n",
    "cv2.imshow('K-Means', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation with grabcut\n",
    "\n",
    "mask = np.zeros(original_image.shape[:2], np.uint8)\n",
    "\n",
    "bb = (50, 50, original_image.shape[1]-50, original_image.shape[0]-50)\n",
    "\n",
    "bgModel = np.zeros((1, 65), np.float64)\n",
    "fgModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "(mask, bgModel, fgModel) = cv2.grabCut(original_image, mask, bb, bgModel, fgModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "output_mask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1)\n",
    "\n",
    "output_mask = (output_mask * 255).astype(\"uint8\")\n",
    "\n",
    "grabcut_result = cv2.bitwise_and(original_image, original_image, mask=output_mask)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('Output mask', output_mask)\n",
    "cv2.imshow('GrabCut', grabcut_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
