{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main paths\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an image\n",
    "\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index = 49\n",
    "\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "original_image = cv2.resize(original_image, (0, 0), fx = 0.15, fy = 0.15)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray and hsv versions\n",
    "\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('HSV', hsv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a box is inside another\n",
    "\n",
    "def is_inside(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    return x2 <= x1 and y2 <= y1 and x2 + w2 >= x1 + w1 and y2 + h2 >= y1 + h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background medium testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hue_tolerance(*args):\n",
    "    global hue_tolerance\n",
    "    hue_tolerance = cv2.getTrackbarPos(\"Hue\", window_name)\n",
    "    process_image()\n",
    "\n",
    "def update_saturation_tolerance(*args):\n",
    "    global saturation_tolerance\n",
    "    saturation_tolerance = cv2.getTrackbarPos(\"Saturation\", window_name)\n",
    "    process_image()\n",
    "\n",
    "def update_value_tolerance(*args):\n",
    "    global value_tolerance\n",
    "    value_tolerance = cv2.getTrackbarPos(\"Value\", window_name)\n",
    "    process_image()\n",
    "\n",
    "def process_image():\n",
    "    lower_limit_0 = max(background_color[0] - hue_tolerance, 0)\n",
    "    upper_limit_0 = min(background_color[0] + hue_tolerance, 180)\n",
    "    lower_limit_1 = max(background_color[1] - saturation_tolerance, 0)\n",
    "    upper_limit_1 = min(background_color[1] + saturation_tolerance, 255)\n",
    "    lower_limit_2 = max(background_color[2] - value_tolerance, 0)\n",
    "    upper_limit_2 = min(background_color[2] + value_tolerance, 255)\n",
    "    \n",
    "    lower_background = np.array([lower_limit_0, lower_limit_1, lower_limit_2])\n",
    "    upper_background = np.array([upper_limit_0, upper_limit_1, upper_limit_2])\n",
    "\n",
    "    blur = cv2.GaussianBlur(hsv_image, (3, 3), 0)\n",
    "    \n",
    "    gray_mask = cv2.inRange(blur, lower_background, upper_background)\n",
    "    non_gray_mask = cv2.bitwise_not(gray_mask)\n",
    "    non_gray_mask = cv2.erode(non_gray_mask, None, iterations=3)\n",
    "    \n",
    "    image = original_image.copy()\n",
    "    result = cv2.bitwise_and(image, image, mask=non_gray_mask)\n",
    "    \n",
    "    contours, _ = cv2.findContours(non_gray_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    img_with_boxes = original_image.copy()\n",
    "\n",
    "    removed = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        inside_other_box = False\n",
    "        for j in range(i+1, len(contours)):\n",
    "            prev_x, prev_y, prev_w, prev_h = cv2.boundingRect(contours[j])\n",
    "            if is_inside((x, y, w, h), (prev_x, prev_y, prev_w, prev_h)):\n",
    "                inside_other_box = True\n",
    "                break\n",
    "        if not inside_other_box:\n",
    "            cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "        else:\n",
    "            removed.append(i)\n",
    "    contours = [contour for i, contour in enumerate(contours) if i not in removed]\n",
    "\n",
    "    combined_image = np.hstack((result, image))\n",
    "    cv2.imshow(window_name, combined_image)\n",
    "\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "hsv_flattened = hsv.reshape((-1, 3))\n",
    "hsv_flattened = hsv_flattened[hsv_flattened[:, 2] > 0]\n",
    "background_color = np.median(hsv_flattened, axis=0)\n",
    "\n",
    "hue_tolerance = 100\n",
    "saturation_tolerance = 100\n",
    "value_tolerance = 100\n",
    "\n",
    "window_name = \"TEST\"\n",
    "cv2.namedWindow(window_name)\n",
    "\n",
    "cv2.createTrackbar(\"Hue\", window_name, hue_tolerance, 180, update_hue_tolerance)\n",
    "cv2.createTrackbar(\"Saturation\", window_name, saturation_tolerance, 255, update_saturation_tolerance)\n",
    "cv2.createTrackbar(\"Value\", window_name, value_tolerance, 255, update_value_tolerance)\n",
    "\n",
    "process_image()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = original_image.copy()\n",
    "gray = gray_image.copy()\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "gaussian = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "reshaped_image = gaussian.reshape((-1, 1))\n",
    "reshaped_image = np.float32(reshaped_image)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "k = 50\n",
    "\n",
    "_, label, center = cv2.kmeans(reshaped_image, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "center = np.uint8(center)\n",
    "kmeans = center[label.flatten()]\n",
    "kmeans = kmeans.reshape((gaussian.shape))\n",
    "\n",
    "max_value = 255\n",
    "threshold_low_value = 100\n",
    "threshold_high_value = 200\n",
    "window_name = \"TEST\"\n",
    "\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "def find_and_draw_contours(low, high, img):\n",
    "    canny_image = cv2.Canny(img, low, high)\n",
    "    contours, _ = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img_with_boxes = original_image.copy()\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    removed = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        inside_other_box = False\n",
    "        for j in range(i+1, len(contours)):\n",
    "            prev_x, prev_y, prev_w, prev_h = cv2.boundingRect(contours[j])\n",
    "            if is_inside((x, y, w, h), (prev_x, prev_y, prev_w, prev_h)):\n",
    "                inside_other_box = True\n",
    "                break\n",
    "        if not inside_other_box:\n",
    "            cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "        else:\n",
    "            removed.append(i)\n",
    "    contours = [contour for i, contour in enumerate(contours) if i not in removed]\n",
    "\n",
    "    canny_image_bgr = cv2.cvtColor(canny_image, cv2.COLOR_GRAY2BGR)\n",
    "    combined_image = np.hstack((canny_image_bgr, img_with_boxes))\n",
    "    cv2.imshow(window_name, combined_image)\n",
    "\n",
    "def alter_low_value(*args):\n",
    "    global threshold_low_value\n",
    "    threshold_low_value = args[0]\n",
    "    find_and_draw_contours(threshold_low_value, threshold_high_value, kmeans)\n",
    "\n",
    "def alter_high_value(*args):\n",
    "    global threshold_high_value\n",
    "    threshold_high_value = args[0]\n",
    "    find_and_draw_contours(threshold_low_value, threshold_high_value, kmeans)\n",
    "\n",
    "cv2.createTrackbar(\"Low\", window_name, threshold_low_value, max_value, alter_low_value)\n",
    "cv2.createTrackbar(\"High\", window_name, threshold_high_value, max_value, alter_high_value)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lego detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_background(hsv):\n",
    "    hsv_flattened = hsv.reshape((-1, 3))\n",
    "    hsv_flattened = hsv_flattened[hsv_flattened[:, 2] > 0]\n",
    "    background_color = np.median(hsv_flattened, axis=0)\n",
    "    return background_color\n",
    "\n",
    "def limits(background_color, hue_tolerance, saturation_tolerance, value_tolerance):\n",
    "    lower_limit_0 = max(background_color[0] - hue_tolerance, 0)\n",
    "    upper_limit_0 = min(background_color[0] + hue_tolerance, 180)\n",
    "    lower_limit_1 = max(background_color[1] - saturation_tolerance, 0)\n",
    "    upper_limit_1 = min(background_color[1] + saturation_tolerance, 255)\n",
    "    lower_limit_2 = max(background_color[2] - value_tolerance, 0)\n",
    "    upper_limit_2 = min(background_color[2] + value_tolerance, 255)\n",
    "    lower_background = np.array([lower_limit_0, lower_limit_1, lower_limit_2])\n",
    "    upper_background = np.array([upper_limit_0, upper_limit_1, upper_limit_2])\n",
    "    return lower_background, upper_background\n",
    "\n",
    "def background_median(hsv):\n",
    "    background_color = median_background(hsv)\n",
    "    hue_tolerance = 20\n",
    "    saturation_tolerance = 90\n",
    "    value_tolerance = 90\n",
    "    lower_background, upper_background = limits(background_color, hue_tolerance, saturation_tolerance, value_tolerance)\n",
    "    blur = cv2.blur(hsv, (5, 5))\n",
    "    gray_mask = cv2.inRange(blur, lower_background, upper_background)\n",
    "    non_gray_mask = cv2.bitwise_not(gray_mask)\n",
    "    non_gray_mask = cv2.erode(non_gray_mask, None, iterations=3)\n",
    "    return non_gray_mask\n",
    "\n",
    "def kmeans_segments(image):\n",
    "    reshaped_image = image.reshape((-1,1))\n",
    "    reshaped_image = np.float32(reshaped_image)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    k = 50\n",
    "    _, label, center = cv2.kmeans(reshaped_image, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    result = center[label.flatten()]\n",
    "    result = result.reshape((image.shape))\n",
    "    return result\n",
    "\n",
    "def canny_edges(gray):\n",
    "    gaussian = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    #kmeans = kmeans_segments(gaussian)\n",
    "    canny = cv2.Canny(gaussian, 100, 200)\n",
    "    return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LEGO pieces detected: 15\n"
     ]
    }
   ],
   "source": [
    "image = original_image.copy()\n",
    "gray = gray_image.copy()\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "bg_median = background_median(hsv)\n",
    "canny = canny_edges(gray)\n",
    "\n",
    "combined_mask = cv2.bitwise_or(bg_median, canny)\n",
    "result = cv2.bitwise_and(image, image, mask=combined_mask)\n",
    "\n",
    "contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "removed = []\n",
    "for i, contour in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    inside_other_box = False\n",
    "    for j in range(i+1, len(contours)):\n",
    "        prev_x, prev_y, prev_w, prev_h = cv2.boundingRect(contours[j])\n",
    "        if is_inside((x, y, w, h), (prev_x, prev_y, prev_w, prev_h)):\n",
    "            inside_other_box = True\n",
    "            break\n",
    "    if not inside_other_box and w * h > 400:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "    else:\n",
    "        removed.append(i)\n",
    "contours = [contour for i, contour in enumerate(contours) if i not in removed]\n",
    "\n",
    "num_lego_pieces = len(contours)\n",
    "print(\"Number of LEGO pieces detected:\", num_lego_pieces)\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.imshow('Background median', bg_median)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.imshow('Combined Mask', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
