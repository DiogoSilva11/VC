{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main paths\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a box is inside another\n",
    "\n",
    "def calculate_intersection_area(square1, square2):\n",
    "    x1, y1, w1, h1 = square1\n",
    "    x2, y2, w2, h2 = square2\n",
    "    \n",
    "    x_intersect = max(x1, x2)\n",
    "    y_intersect = max(y1, y2)\n",
    "    w_intersect = min(x1 + w1, x2 + w2) - x_intersect\n",
    "    h_intersect = min(y1 + h1, y2 + h2) - y_intersect\n",
    "    \n",
    "    if w_intersect <= 0 or h_intersect <= 0:\n",
    "        return 0\n",
    "    \n",
    "    intersection_area = w_intersect * h_intersect\n",
    "    return intersection_area\n",
    "\n",
    "def is_intersected(square1, square2,ratio_threshold):\n",
    "    area_square1 = square1[2] * square1[3]  # area = width * height\n",
    "    area_square2 = square2[2] * square2[3]\n",
    "    area_intersection = calculate_intersection_area(square1, square2)\n",
    "    \n",
    "    ratio1 = area_intersection / area_square1\n",
    "    ratio2 = area_intersection / area_square2\n",
    "    \n",
    "    if ratio1 > ratio_threshold and ratio1 > ratio2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an image\n",
    "\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index = 0\n",
    "\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "original_image = cv2.resize(original_image, (0, 0), fx = 0.15, fy = 0.15)\n",
    "\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray and hsv versions\n",
    "\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Gray', gray_image)\n",
    "cv2.imshow('HSV', hsv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_complexity(gray):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, _ = sift.detectAndCompute(gray, None)\n",
    "    num_keypoints = len(keypoints)\n",
    "    threshold_value = 300\n",
    "    if num_keypoints < threshold_value:\n",
    "        complexity = \"Simple\"\n",
    "    else:\n",
    "        complexity = \"Complex\"\n",
    "    return complexity\n",
    "\n",
    "def median_background(hsv):\n",
    "    hsv_flattened = hsv.reshape((-1, 3))\n",
    "    hsv_flattened = hsv_flattened[hsv_flattened[:, 2] > 0]\n",
    "    background_color = np.median(hsv_flattened, axis=0)\n",
    "    return background_color\n",
    "\n",
    "def limits(background_color, hue_tolerance, saturation_tolerance, value_tolerance):\n",
    "    lower_limit_0 = max(background_color[0] - hue_tolerance, 0)\n",
    "    upper_limit_0 = min(background_color[0] + hue_tolerance, 180)\n",
    "    lower_limit_1 = max(background_color[1] - saturation_tolerance, 0)\n",
    "    upper_limit_1 = min(background_color[1] + saturation_tolerance, 255)\n",
    "    lower_limit_2 = max(background_color[2] - value_tolerance, 0)\n",
    "    upper_limit_2 = min(background_color[2] + value_tolerance, 255)\n",
    "    lower_background = np.array([lower_limit_0, lower_limit_1, lower_limit_2])\n",
    "    upper_background = np.array([upper_limit_0, upper_limit_1, upper_limit_2])\n",
    "    return lower_background, upper_background\n",
    "\n",
    "def background_median(hsv):\n",
    "    background_color = median_background(hsv)\n",
    "    hue_tolerance = 20\n",
    "    saturation_tolerance = 90\n",
    "    value_tolerance = 90\n",
    "    lower_background, upper_background = limits(background_color, hue_tolerance, saturation_tolerance, value_tolerance)\n",
    "    blur = cv2.blur(hsv, (5, 5))\n",
    "    gray_mask = cv2.inRange(blur, lower_background, upper_background)\n",
    "    non_gray_mask = cv2.bitwise_not(gray_mask)\n",
    "    non_gray_mask = cv2.erode(non_gray_mask, None, iterations=3)\n",
    "    return non_gray_mask\n",
    "\n",
    "def kmeans_segments(image):\n",
    "    reshaped_image = image.reshape((-1,1))\n",
    "    reshaped_image = np.float32(reshaped_image)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    k = 50\n",
    "    _, label, center = cv2.kmeans(reshaped_image, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    result = center[label.flatten()]\n",
    "    result = result.reshape((image.shape))\n",
    "    return result\n",
    "\n",
    "def canny_edges(gray):\n",
    "    gaussian = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    #kmeans = kmeans_segments(gaussian)\n",
    "    canny = cv2.Canny(gaussian, 100, 200)\n",
    "    return canny\n",
    "\n",
    "def grab_cut(image):\n",
    "    gaussian = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    mask = np.zeros(gaussian.shape[:2], np.uint8)\n",
    "    size = 50\n",
    "    bb = (size, size, gaussian.shape[1] - size, gaussian.shape[0] - size)\n",
    "    bgModel = np.zeros((1, 65), np.float64)\n",
    "    fgModel = np.zeros((1, 65), np.float64)\n",
    "    (mask, bgModel, fgModel) = cv2.grabCut(gaussian, mask, bb, bgModel, fgModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    output_mask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1)\n",
    "    output_mask = (output_mask * 255).astype(\"uint8\")\n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LEGO pieces detected: 1\n"
     ]
    }
   ],
   "source": [
    "image = original_image.copy()\n",
    "gray = gray_image.copy()\n",
    "hsv = hsv_image.copy()\n",
    "\n",
    "grabcut_mask = grab_cut(image)\n",
    "grabcut_result = cv2.bitwise_and(image, image, mask=grabcut_mask)\n",
    "\n",
    "# apply other masks along with grabcut (TO-DO)\n",
    "bg_median_mask = background_median(hsv)\n",
    "combined_mask = cv2.bitwise_and(grabcut_mask, bg_median_mask)\n",
    "result = cv2.bitwise_and(image, image, mask=combined_mask)\n",
    "\n",
    "contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "ratio_threshold = 0.5\n",
    "removed = []\n",
    "for i, contour in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    inside_other_box = False\n",
    "    for j in range(i+1, len(contours)):\n",
    "        prev_x, prev_y, prev_w, prev_h = cv2.boundingRect(contours[j])\n",
    "        if is_intersected((x, y, w, h), (prev_x, prev_y, prev_w, prev_h), ratio_threshold):\n",
    "            inside_other_box = True\n",
    "            break\n",
    "        elif is_intersected((prev_x, prev_y, prev_w, prev_h),(x,y,w,h), ratio_threshold):\n",
    "            removed.append(j)\n",
    "    if inside_other_box or w * h < 400:\n",
    "        removed.append(i)\n",
    "\n",
    "contours = [contour for i, contour in enumerate(contours) if i not in removed]\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "num_lego_pieces = len(contours)\n",
    "print(\"Number of LEGO pieces detected:\", num_lego_pieces)\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.imshow('Mask', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
