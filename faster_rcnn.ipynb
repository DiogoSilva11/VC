{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Detection - Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# from google.colab import drive # running on google colab\n",
    "from xml.etree import ElementTree as ET\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm\n",
    "\n",
    "!pip install torchmetrics\n",
    "from torchmetrics.detection import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible strategies\n",
    "\n",
    "cut_remaining = 300\n",
    "apply_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive on colab notebook\n",
    "\n",
    "# drive.mount('/content/drive') # running on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data files\n",
    "\n",
    "# !unzip \"/content/drive/MyDrive/02 - tagged1.zip\" -d \"/content\" # running on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major variables\n",
    "\n",
    "photos_dir = 'content/photos' # running locally\n",
    "renders_dir = 'content/renders' # running locally\n",
    "\n",
    "# photos_dir = '/content/photos' # running on google colab\n",
    "# renders_dir = '/content/renders' # running on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    '''\n",
    "    Returns a list of images and labels for each image\n",
    "    '''\n",
    "    image_paths = []\n",
    "    num_legos = []\n",
    "    for subdir, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                n = int(subdir.split(os.sep)[-1])\n",
    "                image_paths.append(os.path.join(subdir, file))\n",
    "                num_legos.append(n)\n",
    "    combined = list(zip(image_paths, num_legos))\n",
    "    combined.sort()\n",
    "    image_paths, num_legos = zip(*combined)\n",
    "    image_paths = np.asarray(image_paths)\n",
    "    num_legos = torch.Tensor(num_legos).to(torch.int64)\n",
    "    return image_paths, num_legos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    '''\n",
    "    Read the xml file and return the bounding box coordinates\n",
    "    '''\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    bounding_boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "        bounding_boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_xml(image_paths):\n",
    "    '''\n",
    "    Parse all XML files corresponding to the given image paths.\n",
    "    '''\n",
    "    bounding_boxes = []\n",
    "    for img_path in image_paths:\n",
    "        xml_path = img_path.replace('.jpg', '.xml')\n",
    "        bounding_boxes.append(parse_xml(xml_path))\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "image_paths, num_legos = load_data(photos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse bounding boxes for all images\n",
    "\n",
    "bounding_boxes = parse_all_xml(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in overall data\n",
    "\n",
    "plt.hist(num_legos, bins=range(1, max(num_legos)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with defined train test split\n",
    "\n",
    "train_test_split = np.genfromtxt('content/train_test_split.csv', delimiter=',', dtype=None, encoding=None) # running locally\n",
    "# train_test_split = np.genfromtxt('/content/drive/MyDrive/train_test_split.csv', delimiter=',', dtype=None, encoding=None) # running on google colab\n",
    "\n",
    "train_test_ids = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "for index, row in enumerate(train_test_split):\n",
    "    if row[1] == '1':\n",
    "      train_test_ids['test'].append(index - 1)\n",
    "    elif row[1] == '0':\n",
    "      train_test_ids['train'].append(index - 1)\n",
    "\n",
    "len(train_test_ids['train']), len(train_test_ids['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in training data\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Training Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and test sets\n",
    "\n",
    "num_legos_test = num_legos[train_test_ids['test']].numpy()\n",
    "test_ids = train_test_ids['test']\n",
    "test_distribution = Counter(num_legos_test)\n",
    "set1_ids, set2_ids = [], []\n",
    "\n",
    "for cls, count in test_distribution.items():\n",
    "    cls_ids = [test_ids[i] for i in range(len(test_ids)) if num_legos_test[i] == cls]\n",
    "    half_count = count // 2\n",
    "    remainder = count % 2\n",
    "    set1_ids.extend(cls_ids[:half_count])\n",
    "    set2_ids.extend(cls_ids[half_count:half_count*2])\n",
    "    if remainder:\n",
    "        if len(set1_ids) <= len(set2_ids):\n",
    "            set1_ids.append(cls_ids[-1])\n",
    "        else:\n",
    "            set2_ids.append(cls_ids[-1])\n",
    "\n",
    "train_test_ids['test'] = np.array(set1_ids)\n",
    "train_test_ids['valid'] = np.array(set2_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in validation and test data\n",
    "\n",
    "num_legos_valid = num_legos[train_test_ids['valid']].numpy()\n",
    "num_legos_test = num_legos[train_test_ids['test']].numpy()\n",
    "\n",
    "valid_distribution = Counter(num_legos_valid)\n",
    "test_distribution = Counter(num_legos_test)\n",
    "    \n",
    "print(\"Valid length:\", len(train_test_ids['valid']))\n",
    "print(\"Test length:\", len(train_test_ids['test']))\n",
    "    \n",
    "print(\"\\nValid class distribution:\")\n",
    "for cls, count in valid_distribution.items():\n",
    "    print(f\"Class {cls}: {count}\")\n",
    "    \n",
    "print(\"\\nTest class distribution:\")\n",
    "for cls, count in test_distribution.items():\n",
    "    print(f\"Class {cls}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling of larger classes in training data\n",
    "\n",
    "indices1 = []\n",
    "indices2 = []\n",
    "\n",
    "for i in train_test_ids['train']:\n",
    "    if num_legos[i] == 1:\n",
    "        indices1.append(i)\n",
    "    elif num_legos[i] == 2:\n",
    "        indices2.append(i)\n",
    "        \n",
    "np.random.shuffle(indices1, )\n",
    "np.random.shuffle(indices2, )\n",
    "\n",
    "leftovers1 = indices1[cut_remaining:]\n",
    "leftovers2 = indices2[cut_remaining:]\n",
    "\n",
    "for i in leftovers1:\n",
    "    train_test_ids['train'].remove(i)\n",
    "for i in leftovers2:\n",
    "    train_test_ids['train'].remove(i)\n",
    "\n",
    "num_legos_train = num_legos[train_test_ids['train']]\n",
    "plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "plt.xlabel('Number of LEGOs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LEGO Training Distribution (Undersampling)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding boxes for train, valid, and test sets\n",
    "\n",
    "train_boxes = [bounding_boxes[i] for i in train_test_ids['train']]\n",
    "valid_boxes = [bounding_boxes[i] for i in train_test_ids['valid']]\n",
    "test_boxes = [bounding_boxes[i] for i in train_test_ids['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegosDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the legos dataset\n",
    "    '''\n",
    "    def __init__(self, images_filenames, num_legos, bounding_boxes, transforms=[], augmented=[]):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.labels = num_legos\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "        self.transforms = transforms\n",
    "        self.augmented = augmented\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        image_filename = self.images_filenames[id]\n",
    "        label = self.labels[id]\n",
    "        bounding_boxes = self.bounding_boxes[id]\n",
    "        image = cv2.imread(image_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        transformation = self.transforms[self.augmented[id]]\n",
    "        image = transformation(image)\n",
    "        scale_w = 640.0 / original_width\n",
    "        scale_h = 640.0 / original_height\n",
    "        scaled_boxes = []\n",
    "        for box in bounding_boxes:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            x_min = int(x_min * scale_w)\n",
    "            y_min = int(y_min * scale_h)\n",
    "            x_max = int(x_max * scale_w)\n",
    "            y_max = int(y_max * scale_h)\n",
    "            scaled_boxes.append([x_min, y_min, x_max, y_max])\n",
    "        target = {\n",
    "            'boxes': torch.tensor(scaled_boxes, dtype=torch.float32),\n",
    "            'labels': torch.ones((label,), dtype=torch.int64)\n",
    "        }\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid and test sets\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = LegosDataset(image_paths[train_test_ids['train']], num_legos[train_test_ids['train']], train_boxes, \n",
    "                             transforms=[transform, augment], augmented=[0]*len(image_paths[train_test_ids['train']]))\n",
    "\n",
    "valid_dataset = LegosDataset(image_paths[train_test_ids['valid']], num_legos[train_test_ids['valid']], valid_boxes, \n",
    "                             transforms=[transform], augmented=[0]*len(image_paths[train_test_ids['valid']]))\n",
    "\n",
    "test_dataset = LegosDataset(image_paths[train_test_ids['test']], num_legos[train_test_ids['test']], test_boxes, \n",
    "                            transforms=[transform], augmented=[0]*len(image_paths[train_test_ids['test']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_paths, num_legos, bounding_boxes, copies=5):\n",
    "    '''\n",
    "    Generate more data by copying images with more than 6 legos\n",
    "    '''\n",
    "    new_image_paths = []\n",
    "    new_num_legos = []\n",
    "    new_bounding_boxes = []\n",
    "    for id in range(len(image_paths)):\n",
    "        if num_legos[id] >= 6:\n",
    "            for _ in range(copies):\n",
    "                new_image_paths.append(image_paths[id])\n",
    "                new_num_legos.append(num_legos[id])\n",
    "                new_bounding_boxes.append(bounding_boxes[id])\n",
    "    return new_image_paths, new_num_legos, new_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling of smaller classes in training data - augmentation\n",
    "\n",
    "if apply_augmentation:\n",
    "    new_image_paths, new_num_legos, new_bounding_boxes = generate_data(\n",
    "                                                            image_paths[train_test_ids['train']], \n",
    "                                                            num_legos[train_test_ids['train']], \n",
    "                                                            train_boxes\n",
    "                                                        )\n",
    "    for img, lbl, bbox in zip(new_image_paths, new_num_legos, new_bounding_boxes):\n",
    "        train_dataset.images_filenames = np.append(train_dataset.images_filenames, img)\n",
    "        train_dataset.labels = torch.cat((train_dataset.labels, torch.tensor([lbl], dtype=torch.int64)))\n",
    "        train_dataset.bounding_boxes.append(bbox)\n",
    "    train_dataset.augmented.extend([1] * len(new_image_paths))\n",
    "    num_legos_train = train_dataset.labels\n",
    "    plt.hist(num_legos_train, bins=range(1, max(num_legos_train)), align='left', rwidth=0.8)\n",
    "    plt.xlabel('Number of LEGOs')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('LEGO Training Distribution (Oversampling)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0 # running locally\n",
    "# num_workers = 2 # running on google colab\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cpu or gpu device for training\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster r-cnn model\n",
    "\n",
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "num_classes = 2\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model in device\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible strategies\n",
    "\n",
    "train_only_head = True\n",
    "train_head_and_rpn = True\n",
    "train_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nms(predictions, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply non-maximum suppression to predictions\n",
    "    \"\"\"\n",
    "    boxes = predictions['boxes']\n",
    "    scores = predictions['scores']\n",
    "    labels = predictions['labels']\n",
    "    keep = torchvision.ops.nms(boxes, scores, iou_threshold=iou_threshold)\n",
    "    boxes = boxes[keep]\n",
    "    scores = scores[keep]\n",
    "    labels = labels[keep]\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map(preds, targets):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Average Precision (mAP) for object detection predictions\n",
    "    \"\"\"\n",
    "    metric = MeanAveragePrecision(box_format='xyxy', iou_type='bbox')\n",
    "    metric.update(preds=preds, target=targets)\n",
    "    values = metric.compute()\n",
    "    return values['map'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(dataloader, model, optimizer=None, is_train=True, grad_accum_steps=2):\n",
    "    '''\n",
    "    Perform one epoch of training/validation/testing\n",
    "    '''\n",
    "    if is_train:\n",
    "        assert optimizer is not None, \"When training, please provide an optimizer\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_loss_classifier = 0.0\n",
    "    total_loss_box_reg = 0.0\n",
    "    total_loss_objectness = 0.0\n",
    "    total_loss_rpn_box_reg = 0.0\n",
    "    total_map = 0.0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for batch, (images, targets) in enumerate(tqdm(dataloader)):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            if is_train:\n",
    "                loss_data = model(images, targets)\n",
    "                loss_classifier = loss_data['loss_classifier']\n",
    "                total_loss_classifier += loss_classifier.item()\n",
    "                loss_box_reg = loss_data['loss_box_reg']\n",
    "                total_loss_box_reg += loss_box_reg.item()\n",
    "                loss_objectness = loss_data['loss_objectness']\n",
    "                total_loss_objectness += loss_objectness.item()\n",
    "                loss_rpn_box_reg = loss_data['loss_rpn_box_reg']\n",
    "                total_loss_rpn_box_reg += loss_rpn_box_reg.item()\n",
    "                losses = (loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg) / grad_accum_steps\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                if (batch + 1) % grad_accum_steps == 0:\n",
    "                    optimizer.step()\n",
    "                total_loss += losses.item() * grad_accum_steps\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(images)\n",
    "                    for preds in predictions:\n",
    "                        preds['boxes'], preds['scores'], preds['labels'] = apply_nms(preds)\n",
    "                    map_score = compute_map(predictions, targets)\n",
    "                    total_map += map_score\n",
    "    avg_loss = total_loss / num_batches if is_train else None\n",
    "    avg_loss_classifier = total_loss_classifier / num_batches if is_train else None\n",
    "    avg_loss_box_reg = total_loss_box_reg / num_batches if is_train else None\n",
    "    avg_loss_objectness = total_loss_objectness / num_batches if is_train else None\n",
    "    avg_loss_rpn_box_reg = total_loss_rpn_box_reg / num_batches if is_train else None\n",
    "    avg_map = total_map / num_batches if not is_train else None\n",
    "    return {\n",
    "        'avg_loss': avg_loss,\n",
    "        'avg_loss_classifier': avg_loss_classifier,\n",
    "        'avg_loss_box_reg': avg_loss_box_reg,\n",
    "        'avg_loss_objectness': avg_loss_objectness,\n",
    "        'avg_loss_rpn_box_reg': avg_loss_rpn_box_reg,\n",
    "        'avg_map': avg_map\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, optimizer, train_history=None, val_history=None):\n",
    "    '''\n",
    "    Train the model\n",
    "    '''\n",
    "    if train_history is None:\n",
    "        train_history = {\n",
    "            'loss': [],\n",
    "            'loss_classifier': [],\n",
    "            'loss_box_reg': [],\n",
    "            'loss_objectness': [],\n",
    "            'loss_rpn_box_reg': []\n",
    "        }\n",
    "    if val_history is None:\n",
    "        val_history = {'map': []}\n",
    "    best_val_map = -np.inf\n",
    "    print(\"Start training...\")\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"\\nEpoch {t+1}/{num_epochs}\")\n",
    "        train_metrics = epoch_iter(train_dataloader, model, optimizer, is_train=True)\n",
    "        train_loss = train_metrics['avg_loss']\n",
    "        train_loss_classifier = train_metrics['avg_loss_classifier']\n",
    "        train_loss_box_reg = train_metrics['avg_loss_box_reg']\n",
    "        train_loss_objectness = train_metrics['avg_loss_objectness']\n",
    "        train_loss_rpn_box_reg = train_metrics['avg_loss_rpn_box_reg']\n",
    "        print(f\"Train loss: {train_loss:.3f}\")\n",
    "        print(f\"  Classifier loss: {train_loss_classifier:.3f}\")\n",
    "        print(f\"  Box regression loss: {train_loss_box_reg:.3f}\")\n",
    "        print(f\"  Objectness loss: {train_loss_objectness:.3f}\")\n",
    "        print(f\"  RPN box regression loss: {train_loss_rpn_box_reg:.3f}\")\n",
    "        val_metrics = epoch_iter(validation_dataloader, model, is_train=False)\n",
    "        val_map = val_metrics['avg_map']\n",
    "        print(f\"Validation mAP: {val_map:.3f}\")\n",
    "        if val_map > best_val_map:\n",
    "            best_val_map = val_map\n",
    "            save_dict = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': t\n",
    "            }\n",
    "            torch.save(save_dict, model_name + '_best_model.pth')\n",
    "        save_dict = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': t\n",
    "        }\n",
    "        torch.save(save_dict, model_name + '_latest_model.pth')\n",
    "        train_history['loss'].append(train_loss)\n",
    "        train_history['loss_classifier'].append(train_loss_classifier)\n",
    "        train_history['loss_box_reg'].append(train_loss_box_reg)\n",
    "        train_history['loss_objectness'].append(train_loss_objectness)\n",
    "        train_history['loss_rpn_box_reg'].append(train_loss_rpn_box_reg)\n",
    "        val_history['map'].append(val_map)\n",
    "    print(\"Finished\")\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation history\n",
    "\n",
    "train_history = {\n",
    "    'loss': [],\n",
    "    'loss_classifier': [],\n",
    "    'loss_box_reg': [],\n",
    "    'loss_objectness': [],\n",
    "    'loss_rpn_box_reg': []\n",
    "}\n",
    "val_history = {'map': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model layers\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "head_layers = ['roi_heads.box_predictor']\n",
    "rpn_layers = [layer[0] for layer in list(model.named_parameters()) if 'rpn' in layer[0]]\n",
    "backbone_layers = [layer[0] for layer in list(model.named_parameters()) if 'backbone' in layer[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_layers(model, layers_to_unfreeze):\n",
    "    '''\n",
    "    Unfreeze the specified layers in the model\n",
    "    '''\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_unfreeze):\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head\n",
    "\n",
    "if train_only_head:\n",
    "    unfreeze_layers(model, head_layers)\n",
    "    optimizer = torch.optim.Adam(model.roi_heads.box_predictor.parameters(), lr=1e-3)\n",
    "    num_epochs = 7\n",
    "    train_history, val_history = train(\n",
    "                                    model,\n",
    "                                    'lego_detector',\n",
    "                                    num_epochs,\n",
    "                                    train_dataloader,\n",
    "                                    valid_dataloader,\n",
    "                                    optimizer,\n",
    "                                    train_history,\n",
    "                                    val_history\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN\n",
    "\n",
    "if train_head_and_rpn:\n",
    "    model = faster_rcnn.to(device)\n",
    "    checkpoint = torch.load('lego_detector_latest_model.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    del checkpoint\n",
    "    unfreeze_layers(model, head_layers)\n",
    "    unfreeze_layers(model, rpn_layers)\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, momentum=0.9, weight_decay=0.0005)\n",
    "    num_epochs = 3\n",
    "    train_history, val_history = train(\n",
    "                                model,\n",
    "                                'lego_detector',\n",
    "                                num_epochs,\n",
    "                                train_dataloader,\n",
    "                                valid_dataloader,\n",
    "                                optimizer,\n",
    "                                train_history,\n",
    "                                val_history\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train head + RPN + backbone\n",
    "\n",
    "if train_all:\n",
    "    torch.cuda.empty_cache()\n",
    "    model = faster_rcnn.to(device)\n",
    "    checkpoint = torch.load('lego_detector_best_model.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    del checkpoint\n",
    "    unfreeze_layers(model, head_layers)\n",
    "    unfreeze_layers(model, rpn_layers)\n",
    "    unfreeze_layers(model, backbone_layers)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0.0005)\n",
    "    num_epochs = 20\n",
    "    train_history, val_history = train(\n",
    "                                model,\n",
    "                                'lego_detector',\n",
    "                                num_epochs,\n",
    "                                train_dataloader,\n",
    "                                valid_dataloader,\n",
    "                                optimizer,\n",
    "                                train_history,\n",
    "                                val_history\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training evolution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingLoss(train_history):\n",
    "    '''\n",
    "    Plot the training loss history of the model\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(train_history['loss'], label='Training Loss')\n",
    "    plt.plot(train_history['loss_classifier'], label='Classifier Loss')\n",
    "    plt.plot(train_history['loss_box_reg'], label='Box Regression Loss')\n",
    "    plt.plot(train_history['loss_objectness'], label='Objectness Loss')\n",
    "    plt.plot(train_history['loss_rpn_box_reg'], label='RPN Box Regression Loss')\n",
    "    plt.title('Training Loss History')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotValidationMAP(val_history):\n",
    "    '''\n",
    "    Plot the validation mAP history of the model\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(val_history['map'], label='Validation mAP')\n",
    "    plt.title('Validation mAP History')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mAP')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training history\n",
    "\n",
    "plotTrainingLoss(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize validation history\n",
    "\n",
    "plotValidationMAP(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "\n",
    "model = faster_rcnn.to(device)\n",
    "checkpoint = torch.load('lego_detector_best_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "\n",
    "test_metrics = epoch_iter(test_dataloader, model, is_train=False)\n",
    "test_map = test_metrics['avg_map']\n",
    "print(f\"\\nTest mAP: {test_map:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataloader, num_images=10):\n",
    "    '''\n",
    "    Display ground truth vs prediction in images\n",
    "    '''\n",
    "    model.eval()\n",
    "    image_count = 0\n",
    "    for batch, (images, targets) in enumerate(dataloader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            predictions = model(images)\n",
    "            for i in range(len(images)):\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "                axes[0].imshow(transforms.ToPILImage()(images[i]))\n",
    "                axes[0].set_title('True')\n",
    "                axes[0].axis('off')\n",
    "                for box in targets[i]['boxes']:\n",
    "                    box = box.cpu().numpy()\n",
    "                    rect = patches.Rectangle(\n",
    "                        (box[0], box[1]), \n",
    "                        box[2] - box[0], \n",
    "                        box[3] - box[1], \n",
    "                        linewidth=2, \n",
    "                        edgecolor='g', \n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    axes[0].add_patch(rect)\n",
    "                axes[1].imshow(transforms.ToPILImage()(images[i]))\n",
    "                axes[1].set_title('Predicted')\n",
    "                axes[1].axis('off')\n",
    "                boxes, scores, labels = apply_nms(predictions[i])\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    if score > 0.5:\n",
    "                        box = box.cpu().numpy()\n",
    "                        rect = patches.Rectangle(\n",
    "                            (box[0], box[1]), \n",
    "                            box[2] - box[0], \n",
    "                            box[3] - box[1], \n",
    "                            linewidth=2, \n",
    "                            edgecolor='b', \n",
    "                            facecolor='none'\n",
    "                        )\n",
    "                        axes[1].add_patch(rect)\n",
    "                        axes[1].text(box[0], box[1], f'{score:.2f}', bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "                plt.show()\n",
    "                image_count += 1\n",
    "                if image_count >= num_images:\n",
    "                    break\n",
    "        if image_count >= num_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view predictions\n",
    "\n",
    "show_predictions(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
