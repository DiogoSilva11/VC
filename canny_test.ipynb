{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannys With Adaptive Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index = 3\n",
    "# Load the image\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "\n",
    "# Resize the image\n",
    "image = original_image.copy()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "gray = clahe.apply(gray)\n",
    "# adaptive thresholding\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 3)\n",
    "#_,thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "canny_image = image.copy()\n",
    "cannys_found_contours = [] \n",
    "\n",
    "edges = cv2.Canny(thresh, 50, 150)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    if w*h > 400:\n",
    "        contour_info = {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'w': w,\n",
    "            'h': h,\n",
    "            'contour': contour \n",
    "        }\n",
    "        cannys_found_contours.append(contour_info)\n",
    "\n",
    "    \n",
    "for found_contour in cannys_found_contours:\n",
    "    x, y, w, h = found_contour['x'], found_contour['y'], found_contour['w'], found_contour['h']\n",
    "    cv2.rectangle(canny_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "\n",
    "cv2.imshow('Original Image', original_image)\n",
    "cv2.imshow('Blur', blur)\n",
    "cv2.imshow('Adaptive Thresholding', thresh)\n",
    "cv2.imshow('Canny Edge Detection', canny_image)\n",
    "cv2.imshow('Canny Corner Detection', edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index =2\n",
    "# Load the image\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "# Resize the image\n",
    "original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "image = original_image.copy()\n",
    "grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "grey = clahe.apply(grey)\n",
    "\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect keypoints\n",
    "keypoints = detector.detect(grey)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "imgKeyPoints = cv2.drawKeypoints(image, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display found keypoints\n",
    "cv2.imshow(\"Keypoints\", imgKeyPoints)\n",
    "cv2.imshow(\"Clahed Image\", grey)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation with Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index =0\n",
    "# Load the image\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "# Resize the image\n",
    "original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "image = original_image.copy()\n",
    "# Convert the image to grayscale\n",
    "grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "grey = clahe.apply(grey)\n",
    "\n",
    "\n",
    "# Apply adaptive thresholding to obtain a binary image\n",
    "adaptive_thresh = cv2.adaptiveThreshold(grey, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "# Apply morphological operations to remove noise and improve contours\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "sure_bg = cv2.dilate(opening, kernel, iterations=2)\n",
    "\n",
    "# Find contours of the lego pieces\n",
    "contours, _ = cv2.findContours(sure_bg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a marker image with different labels for each lego piece\n",
    "markers = np.zeros_like(sure_bg, dtype=np.int32)\n",
    "for i, contour in enumerate(contours):\n",
    "    cv2.drawContours(markers, [contour], 0, i+1, -1)\n",
    "\n",
    "# Apply watershed algorithm\n",
    "cv2.watershed(image, markers)\n",
    "\n",
    "\n",
    "# Overlay the segmented lego pieces on the original image\n",
    "image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
    "\n",
    "# Put a rectangle around each lego piece\n",
    "for i, contour in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Segmented Lego Pieces', image)\n",
    "cv2.imshow('Clahe', grey)\n",
    "cv2.imshow('Original Image', original_image)\n",
    "cv2.imshow('Morphological Opening', opening)\n",
    "cv2.imshow('Sure Background', sure_bg)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Medium Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.  65. 216.]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "output = 'output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "image_index = 40\n",
    "# Load the image\n",
    "original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "# Resize the image\n",
    "original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "image = original_image.copy()\n",
    "\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "# Flatten the HSV image to a 1D array\n",
    "hsv_flattened = hsv.reshape((-1, 3))\n",
    "\n",
    "# Mask out non-zero pixels (non-black pixels)\n",
    "hsv_flattened = hsv_flattened[hsv_flattened[:, 2] > 0]\n",
    "\n",
    "# Calculate the median color (background) in the image\n",
    "background_color = np.median(hsv_flattened, axis=0)\n",
    "print(background_color)\n",
    "tolerance = 110\n",
    "lower_limit_0 = max(background_color[0] - tolerance,0)\n",
    "upper_limit_0 = background_color[0] + tolerance\n",
    "lower_limit_1 = max(background_color[1] - tolerance,0)\n",
    "upper_limit_1 = background_color[1] + tolerance\n",
    "lower_limit_2 = max(background_color[2] - tolerance,0)\n",
    "upper_limit_2 = background_color[2] + tolerance\n",
    "\n",
    "lower_background = np.array([lower_limit_0, lower_limit_1, lower_limit_2])\n",
    "upper_background = np.array([upper_limit_0, upper_limit_1, upper_limit_2])\n",
    "\n",
    "\n",
    "blur = cv2.GaussianBlur(hsv, (9, 9), 0)\n",
    "grey_mask = cv2.inRange(blur, lower_background, upper_background)\n",
    "\n",
    "non_grey_mask = cv2.bitwise_not(grey_mask)\n",
    "\n",
    "result = cv2.bitwise_and(image, image, mask=non_grey_mask)\n",
    "\n",
    "contours, _ = cv2.findContours(non_grey_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    if(w*h < 400):\n",
    "        continue\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Mask OG', grey_mask)\n",
    "cv2.imshow('Mask', non_grey_mask)\n",
    "cv2.imshow('hsv', hsv)\n",
    "cv2.imshow('blur', blur)\n",
    "cv2.imshow('Segmented LEGO pieces', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannys Brute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SCORE] 0/50 with 1734 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 2653 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 5\n",
      "\n",
      "[SCORE] 1/50 with 2356 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 1744 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 1294 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 11\n",
      "\n",
      "[SCORE] 1/50 with 847 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 3 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2334 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 3358 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 5\n",
      "\n",
      "[SCORE] 2/50 with 3260 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 2721 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 2277 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 1733 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 5 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 3244 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 3970 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 5\n",
      "\n",
      "[SCORE] 2/50 with 3899 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 3333 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 9\n",
      "\n",
      "[SCORE] 1/50 with 2896 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 2382 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 7 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 3859 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 4460 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 4228 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 7\n",
      "\n",
      "[SCORE] 3/50 with 3705 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 9\n",
      "\n",
      "[SCORE] 2/50 with 3190 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 2815 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 9 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 4206 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 5082 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 4648 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 4179 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 9\n",
      "\n",
      "[SCORE] 2/50 with 3464 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 2966 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 11 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 4582 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 5508 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 5017 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 4402 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 3812 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 3283 wrong blocks of a total of 307 blocks, with threshold c 1, threshold block size 13 and kernel size 13\n",
      "\n",
      "[SCORE] 3/50 with 968 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 780 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 5\n",
      "\n",
      "[SCORE] 3/50 with 338 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 7\n",
      "\n",
      "[SCORE] 6/50 with 169 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 9\n",
      "\n",
      "[SCORE] 6/50 with 167 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 253 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 3 and kernel size 13\n",
      "\n",
      "[SCORE] 1/50 with 1926 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 1918 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 1250 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 834 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 601 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 11\n",
      "\n",
      "[SCORE] 3/50 with 344 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 5 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2683 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 2845 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 5\n",
      "\n",
      "[SCORE] 1/50 with 2179 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 1643 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 1191 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 11\n",
      "\n",
      "[SCORE] 1/50 with 885 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 7 and kernel size 13\n",
      "\n",
      "[SCORE] 1/50 with 3026 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 3\n",
      "\n",
      "[SCORE] 2/50 with 3150 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 2500 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 2025 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 1582 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 1115 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 9 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 3298 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 3317 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 5\n",
      "\n",
      "[SCORE] 1/50 with 2743 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 7\n",
      "\n",
      "[SCORE] 3/50 with 2311 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 9\n",
      "\n",
      "[SCORE] 3/50 with 1791 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 1371 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 11 and kernel size 13\n",
      "\n",
      "[SCORE] 3/50 with 3386 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 3\n",
      "\n",
      "[SCORE] 2/50 with 3431 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 5\n",
      "\n",
      "[SCORE] 3/50 with 2902 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 7\n",
      "\n",
      "[SCORE] 4/50 with 2496 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 9\n",
      "\n",
      "[SCORE] 3/50 with 1982 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 11\n",
      "\n",
      "[SCORE] 4/50 with 1536 wrong blocks of a total of 307 blocks, with threshold c 2, threshold block size 13 and kernel size 13\n",
      "\n",
      "[SCORE] 7/50 with 458 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 3\n",
      "\n",
      "[SCORE] 6/50 with 180 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 5\n",
      "\n",
      "[SCORE] 3/50 with 207 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 281 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 305 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 306 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 3 and kernel size 13\n",
      "\n",
      "[SCORE] 2/50 with 1186 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 3\n",
      "\n",
      "[SCORE] 2/50 with 911 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 5\n",
      "\n",
      "[SCORE] 3/50 with 502 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 7\n",
      "\n",
      "[SCORE] 6/50 with 239 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 9\n",
      "\n",
      "[SCORE] 6/50 with 142 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 11\n",
      "\n",
      "[SCORE] 3/50 with 195 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 5 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2086 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 1831 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 1238 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 810 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 598 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 380 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 7 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2466 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 2405 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 1701 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 1160 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 850 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 662 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 9 and kernel size 13\n",
      "\n",
      "[SCORE] 1/50 with 2765 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 2642 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 2030 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 1479 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 9\n",
      "\n",
      "[SCORE] 1/50 with 1028 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 11\n",
      "\n",
      "[SCORE] 1/50 with 803 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 11 and kernel size 13\n",
      "\n",
      "[SCORE] 1/50 with 3005 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 2825 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 5\n",
      "\n",
      "[SCORE] 1/50 with 2189 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 1694 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 9\n",
      "\n",
      "[SCORE] 1/50 with 1238 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 945 wrong blocks of a total of 307 blocks, with threshold c 3, threshold block size 13 and kernel size 13\n",
      "\n",
      "[SCORE] 6/50 with 244 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 3\n",
      "\n",
      "[SCORE] 6/50 with 205 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 288 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 307 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 307 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 307 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 3 and kernel size 13\n",
      "\n",
      "[SCORE] 4/50 with 764 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 3\n",
      "\n",
      "[SCORE] 5/50 with 367 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 5\n",
      "\n",
      "[SCORE] 6/50 with 156 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 7\n",
      "\n",
      "[SCORE] 6/50 with 173 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 9\n",
      "\n",
      "[SCORE] 1/50 with 251 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 11\n",
      "\n",
      "[SCORE] 0/50 with 295 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 5 and kernel size 13\n",
      "\n",
      "[SCORE] 1/50 with 1551 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 1210 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 693 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 426 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 9\n",
      "\n",
      "[SCORE] 4/50 with 263 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 11\n",
      "\n",
      "[SCORE] 2/50 with 171 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 7 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2015 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 1689 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 1106 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 7\n",
      "\n",
      "[SCORE] 3/50 with 739 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 521 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 11\n",
      "\n",
      "[SCORE] 6/50 with 346 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 9 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2255 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 3\n",
      "\n",
      "[SCORE] 1/50 with 2029 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 5\n",
      "\n",
      "[SCORE] 1/50 with 1392 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 7\n",
      "\n",
      "[SCORE] 1/50 with 977 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 9\n",
      "\n",
      "[SCORE] 1/50 with 719 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 11\n",
      "\n",
      "[SCORE] 1/50 with 504 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 11 and kernel size 13\n",
      "\n",
      "[SCORE] 0/50 with 2522 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 3\n",
      "\n",
      "[SCORE] 0/50 with 2275 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 5\n",
      "\n",
      "[SCORE] 0/50 with 1678 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 7\n",
      "\n",
      "[SCORE] 0/50 with 1167 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 9\n",
      "\n",
      "[SCORE] 0/50 with 843 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 11\n",
      "\n",
      "[SCORE] 1/50 with 680 wrong blocks of a total of 307 blocks, with threshold c 4, threshold block size 13 and kernel size 13\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "def load_json(filename):\n",
    "        with open(filename) as f:\n",
    "            return json.load(f)\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "canny_output = 'canny_output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "for thresh_c in range(1,5,1):\n",
    "    for thresh_block_size in range(3, 14, 2):\n",
    "        for kernel_size in range(3, 14, 2):\n",
    "            results = []\n",
    "            for image_index in range(len(image_paths)):\n",
    "                contours_list = []\n",
    "                original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "                # Resize the image\n",
    "                original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "                image = original_image.copy()\n",
    "\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "                gray = clahe.apply(gray)\n",
    "                blur = cv2.GaussianBlur(gray, (kernel_size,kernel_size), 0)\n",
    "                thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, thresh_block_size, thresh_c)\n",
    "                #_,thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "                canny_image = image.copy()\n",
    "                cannys_found_contours = [] \n",
    "\n",
    "                edges = cv2.Canny(thresh, 30, 50)\n",
    "                contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for contour in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    if w*h > 400:\n",
    "                        contour_info = {\n",
    "                            'x': x,\n",
    "                            'y': y,\n",
    "                            'w': w,\n",
    "                            'h': h,\n",
    "                            'contour': contour \n",
    "                        }\n",
    "                        cannys_found_contours.append(contour_info)\n",
    "                                \n",
    "                img_info = {\n",
    "                        \"file_name\": image_paths[image_index],\n",
    "                        \"num_colors\": len(cannys_found_contours),\n",
    "                        \"num_detections\": len(cannys_found_contours),\n",
    "                        \"detected_objects\": []  \n",
    "                }\n",
    "                results.append(img_info)    \n",
    "            output = {\n",
    "                \"results\": results\n",
    "            }\n",
    "            with open(f'outputs/canny_adaptative_{thresh_c}_{thresh_block_size}_{kernel_size}.json', 'w') as json_file:\n",
    "                json.dump(output, json_file, indent=4)\n",
    "\n",
    "\n",
    "            output_data = load_json(f'outputs/canny_adaptative_{thresh_c}_{thresh_block_size}_{kernel_size}.json')\n",
    "            solutions_data = load_json('solutions.json')\n",
    "\n",
    "            solutions_dict = {item['file_name']: item for item in solutions_data['results']}\n",
    "            passed_tests = 0\n",
    "            wrong_blocks = 0\n",
    "            all_blocks = 0\n",
    "            total_tests = len(output_data['results'])\n",
    "\n",
    "            for file in output_data['results']:\n",
    "                file_name = file['file_name']\n",
    "                \n",
    "                if file_name in solutions_dict:\n",
    "                    same_colors = file['num_colors'] == solutions_dict[file_name]['num_colors']\n",
    "                    same_detections = file['num_detections'] == solutions_dict[file_name]['num_detections']\n",
    "                    all_blocks += solutions_dict[file_name]['num_detections']\n",
    "                    wrong_blocks += abs(file['num_detections'] - solutions_dict[file_name]['num_detections'])\n",
    "                    if (same_detections):\n",
    "                        passed_tests += 1\n",
    "                        # print(f\"[PASS] {file_name}\")\n",
    "                    else:\n",
    "                        pass\n",
    "                        # print(f\"[FAIL] {file_name} - {file['num_detections']} detections, expected {solutions_dict[file_name]['num_detections']} detections\")\n",
    "                else:\n",
    "                    total_tests -= 1\n",
    "                    print(f\"{file_name}: Not found in solutions\")\n",
    "\n",
    "            print(f\"\\n[SCORE] {passed_tests}/{total_tests} with {wrong_blocks} wrong blocks of a total of {all_blocks} blocks, with threshold c {thresh_c}, threshold block size {thresh_block_size} and kernel size {kernel_size}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Medium Brute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SCORE] 18/50 with 77 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 7 and area threshold 300\n",
      "\n",
      "[SCORE] 21/50 with 74 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 7 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 58 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 7 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 64 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 7 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 72 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 9 and area threshold 300\n",
      "\n",
      "[SCORE] 22/50 with 64 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 9 and area threshold 300\n",
      "\n",
      "[SCORE] 21/50 with 56 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 9 and area threshold 300\n",
      "\n",
      "[SCORE] 21/50 with 59 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 9 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 68 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 11 and area threshold 300\n",
      "\n",
      "[SCORE] 23/50 with 61 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 11 and area threshold 300\n",
      "\n",
      "[SCORE] 22/50 with 55 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 11 and area threshold 300\n",
      "\n",
      "[SCORE] 19/50 with 61 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 11 and area threshold 300\n",
      "\n",
      "[SCORE] 19/50 with 62 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 13 and area threshold 300\n",
      "\n",
      "[SCORE] 22/50 with 58 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 13 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 57 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 13 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 62 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 13 and area threshold 300\n",
      "\n",
      "[SCORE] 22/50 with 55 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 15 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 61 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 15 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 57 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 15 and area threshold 300\n",
      "\n",
      "[SCORE] 17/50 with 66 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 15 and area threshold 300\n",
      "\n",
      "[SCORE] 21/50 with 57 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 17 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 58 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 17 and area threshold 300\n",
      "\n",
      "[SCORE] 19/50 with 58 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 17 and area threshold 300\n",
      "\n",
      "[SCORE] 17/50 with 67 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 17 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 57 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 19 and area threshold 300\n",
      "\n",
      "[SCORE] 19/50 with 59 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 19 and area threshold 300\n",
      "\n",
      "[SCORE] 20/50 with 54 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 19 and area threshold 300\n",
      "\n",
      "[SCORE] 15/50 with 70 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 19 and area threshold 300\n",
      "\n",
      "[SCORE] 17/50 with 71 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 7 and area threshold 400\n",
      "\n",
      "[SCORE] 19/50 with 67 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 7 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 50 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 7 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 61 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 7 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 63 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 9 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 55 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 9 and area threshold 400\n",
      "\n",
      "[SCORE] 22/50 with 51 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 9 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 59 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 9 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 57 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 11 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 55 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 11 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 54 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 11 and area threshold 400\n",
      "\n",
      "[SCORE] 18/50 with 61 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 11 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 55 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 13 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 55 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 13 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 56 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 13 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 62 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 13 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 52 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 15 and area threshold 400\n",
      "\n",
      "[SCORE] 19/50 with 53 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 15 and area threshold 400\n",
      "\n",
      "[SCORE] 22/50 with 55 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 15 and area threshold 400\n",
      "\n",
      "[SCORE] 18/50 with 65 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 15 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 55 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 17 and area threshold 400\n",
      "\n",
      "[SCORE] 18/50 with 57 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 17 and area threshold 400\n",
      "\n",
      "[SCORE] 19/50 with 60 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 17 and area threshold 400\n",
      "\n",
      "[SCORE] 17/50 with 70 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 17 and area threshold 400\n",
      "\n",
      "[SCORE] 20/50 with 56 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 19 and area threshold 400\n",
      "\n",
      "[SCORE] 17/50 with 58 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 19 and area threshold 400\n",
      "\n",
      "[SCORE] 21/50 with 55 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 19 and area threshold 400\n",
      "\n",
      "[SCORE] 15/50 with 72 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 19 and area threshold 400\n",
      "\n",
      "[SCORE] 19/50 with 61 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 7 and area threshold 500\n",
      "\n",
      "[SCORE] 18/50 with 60 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 7 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 51 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 7 and area threshold 500\n",
      "\n",
      "[SCORE] 21/50 with 61 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 7 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 60 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 9 and area threshold 500\n",
      "\n",
      "[SCORE] 21/50 with 56 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 9 and area threshold 500\n",
      "\n",
      "[SCORE] 21/50 with 53 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 9 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 62 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 9 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 55 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 11 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 53 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 11 and area threshold 500\n",
      "\n",
      "[SCORE] 22/50 with 53 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 11 and area threshold 500\n",
      "\n",
      "[SCORE] 19/50 with 61 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 11 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 54 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 13 and area threshold 500\n",
      "\n",
      "[SCORE] 19/50 with 53 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 13 and area threshold 500\n",
      "\n",
      "[SCORE] 22/50 with 55 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 13 and area threshold 500\n",
      "\n",
      "[SCORE] 18/50 with 66 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 13 and area threshold 500\n",
      "\n",
      "[SCORE] 21/50 with 52 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 15 and area threshold 500\n",
      "\n",
      "[SCORE] 18/50 with 55 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 15 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 56 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 15 and area threshold 500\n",
      "\n",
      "[SCORE] 16/50 with 70 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 15 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 51 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 17 and area threshold 500\n",
      "\n",
      "[SCORE] 18/50 with 57 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 17 and area threshold 500\n",
      "\n",
      "[SCORE] 20/50 with 56 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 17 and area threshold 500\n",
      "\n",
      "[SCORE] 16/50 with 72 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 17 and area threshold 500\n",
      "\n",
      "[SCORE] 19/50 with 54 wrong blocks of a total of 307 blocks of tolerance 100, kernel size 19 and area threshold 500\n",
      "\n",
      "[SCORE] 19/50 with 55 wrong blocks of a total of 307 blocks of tolerance 105, kernel size 19 and area threshold 500\n",
      "\n",
      "[SCORE] 18/50 with 57 wrong blocks of a total of 307 blocks of tolerance 110, kernel size 19 and area threshold 500\n",
      "\n",
      "[SCORE] 17/50 with 73 wrong blocks of a total of 307 blocks of tolerance 115, kernel size 19 and area threshold 500\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "def load_json(filename):\n",
    "        with open(filename) as f:\n",
    "            return json.load(f)\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "canny_output = 'canny_output.json'\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "for area_threshold in range(300, 600, 100):\n",
    "    for kernel_size in range(7, 21, 2):\n",
    "        for tolerance in range(100, 120, 5):\n",
    "            results = []\n",
    "\n",
    "            for image_index in range(len(image_paths)):\n",
    "                contours_list = []\n",
    "                original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "                # Resize the image\n",
    "                original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "                image = original_image.copy()\n",
    "\n",
    "                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                    # Flatten the HSV image to a 1D array\n",
    "                hsv_flattened = hsv.reshape((-1, 3))\n",
    "\n",
    "                # Mask out non-zero pixels (non-black pixels)\n",
    "                hsv_flattened = hsv_flattened[hsv_flattened[:, 2] > 0]\n",
    "\n",
    "                # Calculate the median color (background) in the image\n",
    "                background_color = np.median(hsv_flattened, axis=0)\n",
    "                lower_limit_0 = max(background_color[0] - tolerance,0)\n",
    "                upper_limit_0 = min(background_color[0] + tolerance,255)\n",
    "                lower_limit_1 = max(background_color[1] - tolerance,0)\n",
    "                upper_limit_1 = min(background_color[1] + tolerance,255)\n",
    "                lower_limit_2 = max(background_color[2] - tolerance,0)\n",
    "                upper_limit_2 = min(background_color[2] + tolerance,255)\n",
    "\n",
    "                lower_background = np.array([lower_limit_0, lower_limit_1, lower_limit_2])\n",
    "                upper_background = np.array([upper_limit_0, upper_limit_1, upper_limit_2])\n",
    "\n",
    "\n",
    "                blur = cv2.GaussianBlur(hsv, (kernel_size, kernel_size), 0)\n",
    "                grey_mask = cv2.inRange(blur, lower_background, upper_background)\n",
    "\n",
    "                non_grey_mask = cv2.bitwise_not(grey_mask)\n",
    "\n",
    "                result = cv2.bitwise_and(image, image, mask=non_grey_mask)\n",
    "\n",
    "                contours, _ = cv2.findContours(non_grey_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for contour in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    if(w*h < area_threshold):\n",
    "                        continue\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    contours_list.append(contour)\n",
    "\n",
    "                img_info = {\n",
    "                        \"file_name\": image_paths[image_index],\n",
    "                        \"num_colors\": len(contours_list),\n",
    "                        \"num_detections\": len(contours_list),\n",
    "                        \"detected_objects\": []  \n",
    "                }\n",
    "                results.append(img_info)    \n",
    "            output = {\n",
    "                \"results\": results\n",
    "            }\n",
    "            with open(f'outputs/background_median_{tolerance}_{kernel_size}_{area_threshold}.json', 'w') as json_file:\n",
    "                json.dump(output, json_file, indent=4)\n",
    "\n",
    "            \n",
    "            output_data = load_json(f'outputs/background_median_{tolerance}_{kernel_size}_{area_threshold}.json')\n",
    "            solutions_data = load_json('solutions.json')\n",
    "\n",
    "            solutions_dict = {item['file_name']: item for item in solutions_data['results']}\n",
    "            passed_tests = 0\n",
    "            wrong_blocks = 0\n",
    "            all_blocks = 0\n",
    "            total_tests = len(output_data['results'])\n",
    "\n",
    "            for file in output_data['results']:\n",
    "                file_name = file['file_name']\n",
    "                \n",
    "                if file_name in solutions_dict:\n",
    "                    same_colors = file['num_colors'] == solutions_dict[file_name]['num_colors']\n",
    "                    same_detections = file['num_detections'] == solutions_dict[file_name]['num_detections']\n",
    "                    all_blocks += solutions_dict[file_name]['num_detections']\n",
    "                    wrong_blocks += abs(file['num_detections'] - solutions_dict[file_name]['num_detections'])\n",
    "                    if (same_detections):\n",
    "                        passed_tests += 1\n",
    "                       # print(f\"[PASS] {file_name}\")\n",
    "                    else:\n",
    "                        pass\n",
    "                       # print(f\"[FAIL] {file_name} - {file['num_detections']} detections, expected {solutions_dict[file_name]['num_detections']} detections\")\n",
    "                else:\n",
    "                    total_tests -= 1\n",
    "                    print(f\"{file_name}: Not found in solutions\")\n",
    "\n",
    "            print(f\"\\n[SCORE] {passed_tests}/{total_tests} with {wrong_blocks} wrong blocks of a total of {all_blocks} blocks of tolerance {tolerance}, kernel size {kernel_size} and area threshold {area_threshold}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "images_dir = './samples'\n",
    "input = 'input.json'\n",
    "canny_output = 'canny_output.json'\n",
    "results = []\n",
    "with open(input, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "image_paths = data['image_files']\n",
    "for image_index in range(len(image_paths)):\n",
    "    original_image = cv2.imread(os.path.join(images_dir, image_paths[image_index]))\n",
    "\n",
    "    # Resize the image\n",
    "    original_image = cv2.resize(original_image, (0, 0), fx=0.15, fy=0.15)\n",
    "    image = original_image.copy()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply median blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    canny_image = image.copy()\n",
    "    cannys_found_contours = [] \n",
    "\n",
    "    edges = cv2.Canny(blur, 30, 50)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        if area > 10:\n",
    "            to_place = True\n",
    "            cannys_found_contours_copy = cannys_found_contours.copy()\n",
    "            for existing_contour_info in cannys_found_contours:\n",
    "                existing_contour = existing_contour_info['contour']\n",
    "                existing_x, existing_y, existing_w, existing_h = existing_contour_info['x'], existing_contour_info['y'], existing_contour_info['w'], existing_contour_info['h']\n",
    "                \n",
    "                intersect_x1 = max(x, existing_x)\n",
    "                intersect_y1 = max(y, existing_y)\n",
    "                intersect_x2 = min(x + w, existing_x + existing_w)\n",
    "                intersect_y2 = min(y + h, existing_y + existing_h)\n",
    "                intersect_area = max(0, intersect_x2 - intersect_x1) * max(0, intersect_y2 - intersect_y1)\n",
    "\n",
    "\n",
    "\n",
    "                if intersect_area > 0:\n",
    "                    if((w*h) > (existing_w * existing_h)):\n",
    "                        cannys_found_contours_copy.remove(existing_contour_info)    \n",
    "                    else:\n",
    "                        to_place = False\n",
    "                        break\n",
    "                    \n",
    "\n",
    "            if to_place:\n",
    "                contour_info = {\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'contour': contour \n",
    "                }\n",
    "\n",
    "                cannys_found_contours_copy.append(contour_info)\n",
    "                cannys_found_contours = cannys_found_contours_copy \n",
    "\n",
    "    img_info = {\n",
    "        \"file_name\": image_paths[image_index],\n",
    "        \"num_colors\": len(cannys_found_contours),\n",
    "        \"num_detections\": len(cannys_found_contours),\n",
    "        \"detected_objects\": []  \n",
    "    }\n",
    "    results.append(img_info)\n",
    "\n",
    "output = {\n",
    "    \"results\": results\n",
    "}\n",
    "with open(canny_output, 'w') as json_file:\n",
    "    json.dump(output, json_file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
